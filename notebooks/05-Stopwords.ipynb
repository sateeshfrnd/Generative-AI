{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fe764af-cd7a-45f1-b2d6-986026524b5e",
   "metadata": {},
   "source": [
    "# StopWords\n",
    "\n",
    "Stopwords are common words that are usually filtered out during text processing tasks, especially in Natural Language Processing (NLP). These are words that don't carry significant meaning and are often removed to improve the efficiency and accuracy of text analysis algorithms like search engines, sentiment analysis, and other text mining techniques.\n",
    "\n",
    "Examples of stopwords include: \"the,\" \"is,\" \"in,\" \"and,\" \"a,\" \"of\" and other similar words that appear frequently in the text but don't contribute much to the meaning or content."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f035a4-8eea-49d0-8fbc-ba2e36905bb2",
   "metadata": {},
   "source": [
    "## Why Remove Stopwords?\n",
    "- Reduce noise: Stopwords do not add much value to the understanding of a sentence or document.\n",
    "- Improve performance: Removing stopwords helps to reduce the size of the text data and focus on the more meaningful words.\n",
    "- Save processing power: Algorithms can process documents faster and more efficiently when irrelevant words are excluded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4bd98b2-42f1-428b-9cd3-44d271a0618f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73bd5160-5098-478b-90ad-d7ab7a8e83c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\satee\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28169a08-d0db-4b4c-80f8-6ea5fb787ba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[\\'i\\', \\'me\\', \\'my\\', \\'myself\\', \\'we\\', \\'our\\', \\'ours\\', \\'ourselves\\', \\'you\\', \"you\\'re\", \"you\\'ve\", \"you\\'ll\", \"you\\'d\", \\'your\\', \\'yours\\', \\'yourself\\', \\'yourselves\\', \\'he\\', \\'him\\', \\'his\\', \\'himself\\', \\'she\\', \"she\\'s\", \\'her\\', \\'hers\\', \\'herself\\', \\'it\\', \"it\\'s\", \\'its\\', \\'itself\\', \\'they\\', \\'them\\', \\'their\\', \\'theirs\\', \\'themselves\\', \\'what\\', \\'which\\', \\'who\\', \\'whom\\', \\'this\\', \\'that\\', \"that\\'ll\", \\'these\\', \\'those\\', \\'am\\', \\'is\\', \\'are\\', \\'was\\', \\'were\\', \\'be\\', \\'been\\', \\'being\\', \\'have\\', \\'has\\', \\'had\\', \\'having\\', \\'do\\', \\'does\\', \\'did\\', \\'doing\\', \\'a\\', \\'an\\', \\'the\\', \\'and\\', \\'but\\', \\'if\\', \\'or\\', \\'because\\', \\'as\\', \\'until\\', \\'while\\', \\'of\\', \\'at\\', \\'by\\', \\'for\\', \\'with\\', \\'about\\', \\'against\\', \\'between\\', \\'into\\', \\'through\\', \\'during\\', \\'before\\', \\'after\\', \\'above\\', \\'below\\', \\'to\\', \\'from\\', \\'up\\', \\'down\\', \\'in\\', \\'out\\', \\'on\\', \\'off\\', \\'over\\', \\'under\\', \\'again\\', \\'further\\', \\'then\\', \\'once\\', \\'here\\', \\'there\\', \\'when\\', \\'where\\', \\'why\\', \\'how\\', \\'all\\', \\'any\\', \\'both\\', \\'each\\', \\'few\\', \\'more\\', \\'most\\', \\'other\\', \\'some\\', \\'such\\', \\'no\\', \\'nor\\', \\'not\\', \\'only\\', \\'own\\', \\'same\\', \\'so\\', \\'than\\', \\'too\\', \\'very\\', \\'s\\', \\'t\\', \\'can\\', \\'will\\', \\'just\\', \\'don\\', \"don\\'t\", \\'should\\', \"should\\'ve\", \\'now\\', \\'d\\', \\'ll\\', \\'m\\', \\'o\\', \\'re\\', \\'ve\\', \\'y\\', \\'ain\\', \\'aren\\', \"aren\\'t\", \\'couldn\\', \"couldn\\'t\", \\'didn\\', \"didn\\'t\", \\'doesn\\', \"doesn\\'t\", \\'hadn\\', \"hadn\\'t\", \\'hasn\\', \"hasn\\'t\", \\'haven\\', \"haven\\'t\", \\'isn\\', \"isn\\'t\", \\'ma\\', \\'mightn\\', \"mightn\\'t\", \\'mustn\\', \"mustn\\'t\", \\'needn\\', \"needn\\'t\", \\'shan\\', \"shan\\'t\", \\'shouldn\\', \"shouldn\\'t\", \\'wasn\\', \"wasn\\'t\", \\'weren\\', \"weren\\'t\", \\'won\\', \"won\\'t\", \\'wouldn\\', \"wouldn\\'t\"]'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20da713c-9e96-4461-949c-703c8a643616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample text\n",
    "text = \"This is a simple example demonstrating the use of stopwords in NLTK.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25146c61-c364-41b9-8539-be5236f1c5af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This',\n",
       " 'is',\n",
       " 'a',\n",
       " 'simple',\n",
       " 'example',\n",
       " 'demonstrating',\n",
       " 'the',\n",
       " 'use',\n",
       " 'of',\n",
       " 'stopwords',\n",
       " 'in',\n",
       " 'NLTK',\n",
       " '.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "# Tokenize the text\n",
    "words = word_tokenize(text)\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2fe71cf-fbaf-439a-bc68-f12accd7e5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of English stopwords\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c1a9f67-795a-4f18-a43a-eaef29b6a7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stopwords from the tokenized words\n",
    "filtered_words = [word for word in words if word.lower() not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "726be39d-aaf9-4dfa-a604-2daacf7a1374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['simple', 'example', 'demonstrating', 'use', 'stopwords', 'NLTK', '.']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d43e260-37d9-4120-8db3-dfe6315e0244",
   "metadata": {},
   "source": [
    "After removing stopwords, we are left with the more meaningful words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54902e13-c2bd-4068-b231-84c3c17e197f",
   "metadata": {},
   "source": [
    "## When to Use Stopwords:\n",
    "- **Text Classification:** Removing stopwords can improve the performance of models by focusing on the important words.\n",
    "- **Sentiment Analysis:** Stopwords can dilute the sentiment score, so removing them helps in more accurate sentiment scoring.\n",
    "- **Information Retrieval/Search Engines:** Helps refine search results by ignoring frequently occurring but irrelevant words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ac6d6e-f9a2-4dce-b07c-aea978c90019",
   "metadata": {},
   "source": [
    "## Key Points:\n",
    "- **Stopwords** improve the relevance of text data by filtering out less meaningful words.\n",
    "- The **list of stopwords** can be language-specific and is available in multiple languages in NLTK.\n",
    "- You can **customize the stopwords** list according to your needs (e.g., adding domain-specific stopwords)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
